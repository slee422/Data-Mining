{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "trainFile = sys.argv[1]\n",
    "testFile = sys.argv[2]\n",
    "with open(trainFile) as f:\n",
    "    trainlines = f.readlines()\n",
    "\n",
    "with open(testFile) as o:\n",
    "    testlines = o.readlines()\n",
    "\n",
    "if 'synthetic.social' in sys.argv[1]:\n",
    "    parameter = 120\n",
    "elif 'nursery' in sys.argv[1]:\n",
    "    parameter = 8\n",
    "elif 'led' in sys.argv[1]:\n",
    "    parameter = 7\n",
    "else:\n",
    "    parameter = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "from collections import Counter\n",
    "def most_common(lst):\n",
    "    \"\"\"\n",
    "    Returns most common value in list\n",
    "    \"\"\"\n",
    "    data = Counter(lst)\n",
    "    return max(lst, key=data.get)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "traindf = []\n",
    "for line in trainlines:\n",
    "    traindf.append(line.rstrip('\\n'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "testdf = []\n",
    "for line in testlines:\n",
    "    testdf.append(line.rstrip('\\n'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def count(name, value, target_label, labels):\n",
    "    \"\"\"\n",
    "    Returns a dictionary with the all the attributes and a count of their unique values\n",
    "    \"\"\"\n",
    "    dictionary = {} \n",
    "    for att in name[0]:\n",
    "        dictionary[att] = {}\n",
    "    for idx, label in enumerate(labels):\n",
    "        for col in range(len(name[idx])):\n",
    "            if not value[idx][col] in dictionary[name[idx][col]]:\n",
    "                dictionary[name[idx][col]][value[idx][col]] = 0\n",
    "            if label==target_label:\n",
    "                dictionary[name[idx][col]][value[idx][col]] += 1\n",
    "    return dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def preprocess(data):\n",
    "    \"\"\"\n",
    "    Preprocesses the data to retrieve important information\n",
    "    \"\"\"\n",
    "    # list of train labels\n",
    "    labels = []\n",
    "    for line in range(len(data)):\n",
    "        labels.append(data[line][0])\n",
    "    # define size of training set\n",
    "    total = len(labels)\n",
    "    # tuples of the <index>:<value>...<index>:<value> of each line of data as type string\n",
    "    tups = []\n",
    "    for line in range(len(data)):\n",
    "        tups.append(tuple(re.match(\"(.*):(.*)\", data[line][2:]).group().replace(\":\",\",\").replace(\" \",\",\").split(\",\")))\n",
    "    \n",
    "    return labels, total, tups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_count(labels, tups):\n",
    "    \"\"\"\n",
    "    Returns class dictionary, attribute dictionary, attributes, attribute & values matrices\n",
    "    \"\"\"\n",
    "    # list of tuples( attribute names ) for each line of data\n",
    "    attribute_name = []\n",
    "    for line in range(len(tups)):\n",
    "        line_atts = tuple(tups[line][value] for value in range(len(tups[0])) if (value%2==0))\n",
    "        attribute_name.append(line_atts)\n",
    "    attribute_list = list(attribute_name[0])\n",
    "    attribute_val = []\n",
    "    for line in range(len(tups)):\n",
    "        line_vals = tuple(tups[line][value] for value in range(len(tups[0])) if (value%2!=0))\n",
    "        attribute_val.append(line_vals)\n",
    "    # Count the unique values for each attribute out of four total\n",
    "    count_val = {}\n",
    "    for attribute in attribute_name[0]:\n",
    "        count_val[attribute]={}\n",
    "    for line in range(len(attribute_name)):\n",
    "        for col in range(len(attribute_name[line])):\n",
    "            if not attribute_val[line][col] in count_val[attribute_name[line][col]]:\n",
    "                count_val[attribute_name[line][col]][attribute_val[line][col]] = 1\n",
    "            else: count_val[attribute_name[line][col]][attribute_val[line][col]] += 1\n",
    "    # Count the number of values in a attribute given a class label\n",
    "    count_class = {}\n",
    "    for lab in set(labels):\n",
    "        count_class[lab] = count(attribute_name, attribute_val, lab, labels)\n",
    "\n",
    "    return count_class, count_val, attribute_list, attribute_name, attribute_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_labels, train_total, train_tups = preprocess(traindf)\n",
    "train_dc, train_dv, train_attributes, train_name, train_values = get_count(train_labels, train_tups)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_labels, test_total, test_tups = preprocess(testdf)\n",
    "test_dc, test_dv, test_attributes, test_name, test_values = get_count(test_labels, test_tups)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def filter_tuples(tuples, a_names, a_values, labels, best, value):\n",
    "    new_tuples = []\n",
    "    new_labels = []\n",
    "    for i in range(len(a_names)):\n",
    "        for j in range(len(a_names[0])):\n",
    "            if ((best==a_names[i][j]) and (value==a_values[i][j])):\n",
    "                new_tuples.append(tuples[i])\n",
    "                new_labels.append(labels[i])\n",
    "    return new_tuples, new_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_values(values, target_att):\n",
    "    \"\"\"\n",
    "    values is a dict; target_att will be splitting attribute for decision tree\n",
    "    \"\"\"\n",
    "    return values[target_att].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def gini(classes, values, target_att, att_value):\n",
    "    \"\"\"\n",
    "    Calculate gini(D) without dividing by total D\n",
    "    \"\"\"\n",
    "    b = []\n",
    "    for cl in classes.keys():\n",
    "        b.append(classes[cl][target_att][att_value])\n",
    "    g = values[target_att][att_value]\n",
    "    t = 1\n",
    "    for j in range(len(b)):\n",
    "        t -= (b[j]/values[target_att][att_value])**2\n",
    "    f = g*t\n",
    "    return f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def gini_split(classes, values, target_att):\n",
    "    \"\"\"\n",
    "    Calculates gini split.\n",
    "    classes = dictionary of labels and count of attribute values (count_class)\n",
    "    values = dictionary of unique values for each attribute (count_val)\n",
    "    \"\"\"\n",
    "    g_split = []\n",
    "    for key in values[target_att].keys():\n",
    "        g_split.append(gini(classes, values, target_att, key))\n",
    "    return sum(g_split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def splitting_attribute(classes, values, att_list):\n",
    "    \"\"\"\n",
    "    Choose attribute to split on \n",
    "    \"\"\"\n",
    "    a_list = att_list\n",
    "    ls = []\n",
    "    a = str()\n",
    "    for att in a_list:\n",
    "        ls.append(gini_split(classes, values, att))\n",
    "    for idx, v in enumerate(ls):\n",
    "        if v==min(ls):\n",
    "            a = a_list[idx]\n",
    "    return a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def majority_class(classes, labels, target_attr):\n",
    "    \"\"\"\n",
    "    Returns majority class of target attribute \n",
    "    \"\"\"\n",
    "    count_list = []\n",
    "    label = []\n",
    "    if (target_attr == 0):\n",
    "        lab = most_common(labels)\n",
    "    else:\n",
    "        for cls in classes.keys():\n",
    "            temp = classes[cls]\n",
    "            count_list.append(sum(temp[target_attr].values()))\n",
    "            label.append(cls)\n",
    "        for idx, val in enumerate(count_list):\n",
    "            if val==max(count_list):\n",
    "                lab = label[idx]\n",
    "    return lab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_tree(tuples, labels, attributes, height):\n",
    "    \"\"\"\n",
    "    Returns a new decision tree based on the examples given.\n",
    "    \"\"\" \n",
    "    max_depth = height\n",
    "#     classes, values, attributes, labels, total, attribute_name, attribute_values = preprocess(data)\n",
    "    dclasses, dvalues, new_attributes, a_names, a_values = get_count(labels, tuples)\n",
    "    #     Create a node N\n",
    "    tree = {}\n",
    "#     If tuples in D are all from same class, C, return N as a leaf node labeled class C;\n",
    "    if (labels.count(labels[0]) == len(labels)):\n",
    "        return labels[0]\n",
    "#     If attribute list empty, return N as a leaf node labeled w/majority class in D;majority voting\n",
    "    elif not tuples or (len(new_attributes) <= 0) or max_depth==len(new_attributes):\n",
    "        return majority_class(dclasses, labels, 0)\n",
    "    else:\n",
    "        max_depth += 1\n",
    "#     Apply Attribute selection method(D, attribute list) to ﬁnd the “best” splitting criterion\n",
    "        best = splitting_attribute(dclasses, dvalues, new_attributes)\n",
    "#     Label node N with splitting criterion\n",
    "        tree= {best: {}}\n",
    "#     For full split, attribute list = att list −splitting att; //remove splitting attribute \n",
    "        if best in new_attributes:\n",
    "            attr_list = [attr for attr in new_attributes if attr != best]\n",
    "#     For each outcome j of splitting criterion // partition tuples, grow subtrees for each partition \n",
    "        for val in get_values(dvalues, best):\n",
    "#         Let Dj be the set of data tuples in D satisfying outcome j; // a partition \n",
    "            new_tuples, new_labels = filter_tuples(tuples, a_names, a_values, labels, best, val)\n",
    "            subtree = create_tree(new_tuples, new_labels, attr_list, max_depth)\n",
    "#         if Dj is empty then attach a leaf labeled with the majority class in D to node N\n",
    "            if not subtree:\n",
    "                tree[best][val] = majority_class(dclasses, labels, 0)\n",
    "#         else attach the node returned by Generate decision tree(Dj, attribute list) to node N; \n",
    "            else: tree[best][val] = subtree\n",
    "#     endfor\n",
    "#     return N;\n",
    "    return tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def classify(tree, tup, labels):\n",
    "    t = tup\n",
    "    class_label = tree\n",
    "    a_name = tuple(tup[index] for index in range(len(tup)) if (index%2 == 0))\n",
    "    a_value = tuple(tup[index] for index in range(len(tup)) if (index%2 != 0))\n",
    "    if(isinstance(tree, dict)):\n",
    "        copy_tree = tree.copy()\n",
    "        for k, v in copy_tree.items():\n",
    "            index = a_name.index(k)\n",
    "            value = a_value[index]\n",
    "            try:\n",
    "                class_label = classify(copy_tree[k][value], t, labels)\n",
    "            except KeyError:\n",
    "                class_label = most_common(labels)\n",
    "                    \n",
    "    return class_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def predict_labels(tree, tuplist, trn_labels):\n",
    "    labels = []\n",
    "    for i in range(len(tuplist)):\n",
    "        labels.append(classify(tree, tuplist[i], trn_labels))\n",
    "    return labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_tree = create_tree(train_tups, train_labels, train_attributes, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predictions = predict_labels(train_tree, test_tups, train_labels)\n",
    "k = len(set(train_labels))\n",
    "uniq_labels= sorted(list(set(train_labels)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "actual_idx = [uniq_labels.index(test_labels[x]) for x in range(len(test_labels))]\n",
    "predicted_idx = [uniq_labels.index(predictions[x]) for x in range(len(predictions))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "combine_idx =[]\n",
    "for i in range(len(actual_idx)):\n",
    "    combine_idx.append(tuple([actual_idx[i], predicted_idx[i]]))\n",
    "\n",
    "count_idx = []\n",
    "for i in set(combine_idx):\n",
    "    count_idx.append(combine_idx.count(i))\n",
    "count_idx\n",
    "\n",
    "row = []\n",
    "l = 0\n",
    "while(l!=len(uniq_labels)):\n",
    "    m = 0\n",
    "    while(m!=len(uniq_labels)):\n",
    "        row.append(combine_idx.count((l,m)))\n",
    "        m +=1\n",
    "    l +=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def createMatrix(rowCount, colCount, dataList):\n",
    "    \"\"\"\n",
    "    Returns a matrix in list form\n",
    "    \"\"\" \n",
    "    matrix = []\n",
    "    for i in range(rowCount):\n",
    "        rowList = []\n",
    "        for j in range(colCount):\n",
    "            rowList.append(dataList[rowCount * i + j])\n",
    "        matrix.append(rowList)\n",
    "    return matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix = createMatrix(k, k, row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for row in confusion_matrix:\n",
    "    print(' '.join(map(str,row)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
